{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- MFT(Minimum Functionality Test): focuses on evaluating whether a model has the basic functionality \n",
    "- DIR(Directional Expectation test). determine whether a modelâ€™s predictions are consistent with a prior expectation or hypothesis \n",
    "- INV (Invariance testing) is a type of testing in ML that checks whether a model is invariant to certain transformations or changes in the input data. \n",
    "\n",
    "\n",
    "\n",
    "ref:\n",
    "- https://www.godeltech.com/how-to-automate-the-testing-process-for-machine-learning-systems/\n",
    "\n",
    "To test each test case fail or not, depends on the `Label` that provide in line like this\n",
    "```test = MFT(**t, labels=0, name=name, capability = 'Vocabulary',description=desc)```\n",
    "ps. it can be changed depends on the type(MFT, DIR, or INV) that select to test \n",
    "\n",
    "For the sentimental revise\n",
    "- 'negative': 0\n",
    "- 'positive': 2\n",
    "- 'neutral': 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import checklist\n",
    "import spacy\n",
    "import itertools\n",
    "\n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.perturb import Perturb\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<checklist.text_generation.TextGenerator at 0x22846604850>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor = checklist.editor.Editor() # creates an instance of the Editor class \n",
    "editor.tg # generate the new text data of the Checklist library fro the testing model and suggest the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "r = csv.DictReader(open('Tweets.csv')) # read file Tweets.csv (airline dataset)\n",
    "\n",
    "# Initialize array to store the data\n",
    "labels = []\n",
    "confs = []\n",
    "airlines = []\n",
    "tdata = []\n",
    "reasons = []\n",
    "\n",
    "# Append data from csv file into the array\n",
    "for row in r:\n",
    "    sentiment, conf, airline, text = row['airline_sentiment'], row['airline_sentiment_confidence'], row['airline'], row['text']\n",
    "    labels.append(sentiment) # this is airline_sentiment contain `positive`, `negative`, and `neutral`\n",
    "    confs.append(conf) # append the score of confidence\n",
    "    airlines.append(airline) # append airline name\n",
    "    tdata.append(text) # append the text into tdata array\n",
    "    reasons.append(row['negativereason']) \n",
    "\n",
    "mapping = {'negative': 0, 'positive': 2, 'neutral': 1} # define to map the label data into number\n",
    "labels = np.array([mapping[x] for x in labels]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the model from Spacy library used for the NLP task below in the parsed_question. to parse data into the pipeline\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn data into pipeline then convert to list, and saved the result in `parsed_data`\n",
    "sentences = tdata\n",
    "parsed_data = list(nlp.pipe(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test suite is container for the unit test. used for the test case.\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFTs focus on basic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the noun in the array\n",
    "air_noun = ['flight', 'seat', 'pilot', 'staff', 'service', 'customer service', 'aircraft', 'plane', 'food', 'cabin crew', 'company', 'airline', 'crew']\n",
    "\n",
    "# add the noun array in to lexicon which can use like mask. On this line, it will be used in {air_noun} which can be changed when testing.\n",
    "editor.add_lexicon('air_noun', air_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kafka\\anaconda3\\Lib\\site-packages\\checklist\\text_generation.py:171: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  to_pred = torch.tensor(to_pred, device=self.device).to(torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great, good, excellent, amazing, incredible, extraordinary, terrible, expensive, bad, fantastic, wonderful, interesting, new, nice, unusual, important, exceptional, beautiful, American, ordinary, different, efficient, poor, enormous, special, average, real, awful, easy, professional, awesome, horrible, fine, huge, perfect, remarkable, international, simple, terrific, solid\n"
     ]
    }
   ],
   "source": [
    "# suggest the mask from the context. In this context mask provided the adjective.\n",
    "print(', '.join(editor.suggest('It was {a:mask} {air_noun}.')[:40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define positive, negative, and neutral adjective\n",
    "pos_adj = ['good', 'great', 'excellent', 'amazing', 'extraordinary', 'beautiful', 'fantastic', 'nice', 'incredible', 'exceptional', 'awesome', 'perfect', 'fun', 'happy', 'adorable', 'brilliant', 'exciting', 'sweet', 'wonderful']\n",
    "neg_adj = ['awful', 'bad', 'horrible', 'weird', 'rough', 'lousy', 'unhappy', 'average', 'difficult', 'poor', 'sad', 'frustrating', 'hard', 'lame', 'nasty', 'annoying', 'boring', 'creepy', 'dreadful', 'ridiculous', 'terrible', 'ugly', 'unpleasant']\n",
    "neutral_adj = ['American', 'international',  'commercial', 'British', 'private', 'Italian', 'Indian', 'Australian', 'Israeli', ]\n",
    "\n",
    "# add dictionary of word into object \n",
    "editor.add_lexicon('pos_adj', pos_adj, overwrite=True)\n",
    "editor.add_lexicon('neg_adj', neg_adj, overwrite=True )\n",
    "editor.add_lexicon('neutral_adj', neutral_adj, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liked, enjoyed, like, appreciated, appreciate, loved, enjoy, love, miss, missed, respect, got, prefer, wanted, needed, admired, hate, recommend, preferred, value, disliked, respected, dislike, hated, need, used, felt, valued, want, took, admire, feel, trust, dig, understood, noticed, underestimated, welcomed, tried, found, dug, understand, adore, use, get, praised, did, likes, left, mean, considered, think, saw, favor, welcome, liking, trusted, had, regret, remember, cherish, helped, treasure, supported, cherished, picked, have, enjoying, followed, consider, bought, support, compliment, thank, met, chose, credit, commend, know, applaud, thought, believe, rate, see, lost, watched, LOVE, embraced, minded, impressed, experienced, envy, blame, packed, improved, follow, fancy, take, recommended, underestimate, choose, was, saved, expected, thanked, beat, owe, mind, forgive, joined, learned, resent, do, knew, hit, read, leave, regretted, earned, deserved, made, finished, anticipated, rocked, drove, caught, LIKE, help, handled, grabbed, spoiled, crave, reviewed, meet, cleaned, try, desired, hope, requested, changed, told, tested, surprised, stressed, recruited, praise, doubt, worked, favored, find, hired, am, wish, checked, researched, Like, survived, ate, planned, rode, managed, ordered, coveted, sampled, crashed, dreaded, timed, canceled, brought, ended, worth, spent, applauded, heard, pushed, delayed, flew, eat, rushed, cancelled, tasted, paid, shortened, salute, thanks, received, filled, skipped, exited, sold, slept, relaxed, edited, dread, blessed, deserve, cooked, ruined, fit, booked\n"
     ]
    }
   ],
   "source": [
    "# suggest the mask from the context. In this context mask provided the verb\n",
    "print(', '.join(editor.suggest('I really {mask} the {air_noun}.')[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define positive, negative, and neutral verb\n",
    "pos_verb_present = ['like', 'enjoy', 'appreciate', 'love',  'recommend', 'admire', 'value', 'welcome']\n",
    "neg_verb_present = ['hate', 'dislike', 'regret',  'abhor', 'dread', 'despise' ]\n",
    "neutral_verb_present = ['see', 'find']\n",
    "\n",
    "# define past participle verb\n",
    "pos_verb_past = ['liked', 'enjoyed', 'appreciated', 'loved', 'admired', 'valued', 'welcomed']\n",
    "neg_verb_past = ['hated', 'disliked', 'regretted',  'abhorred', 'dreaded', 'despised']\n",
    "neutral_verb_past = ['saw', 'found']\n",
    "\n",
    "# add dictionary of word into object \n",
    "editor.add_lexicon('pos_verb_present', pos_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_present', neg_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_present', neutral_verb_present, overwrite=True)\n",
    "editor.add_lexicon('pos_verb_past', pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_past', neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_past', neutral_verb_past, overwrite=True)\n",
    "\n",
    "# also add into `pos_verb`, `neg_verb`, `neutral_verb` object\n",
    "editor.add_lexicon('pos_verb', pos_verb_present+ pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb', neg_verb_present + neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb', neutral_verb_present + neutral_verb_past, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add individual word test: positive verb\n",
    "test = MFT(pos_adj + pos_verb_present + pos_verb_past, labels=2)\n",
    "suite.add(test, 'single positive words', 'Vocabulary', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add individual word test: negative verb\n",
    "test = MFT(neg_adj + neg_verb_present + neg_verb_past, labels=0)\n",
    "suite.add(test, 'single negative words', 'Vocabulary', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add individual word test: neutral verb\n",
    "test = MFT(neutral_adj + neutral_verb_present + neutral_verb_past, labels=1)\n",
    "suite.add(test, 'single neutral words', 'Vocabulary', 'TODO_DESCRIPTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the test. On each line provided different context with the mask provided\n",
    "t = editor.template('{it} {air_noun} {be} {pos_adj}.', it=['The', 'This', 'That'], be=['is', 'was'], labels=2, save=True) #need to define first\n",
    "t += editor.template('{it} {be} {a:pos_adj} {air_noun}.', it=['It', 'This', 'That'], be=['is', 'was'], labels=2, save=True) #after first line needed to use += to append test on the list\n",
    "t += editor.template('{i} {pos_verb} {the} {air_noun}.', i=['I', 'We'], the=['this', 'that', 'the'], labels=2, save=True)\n",
    "t += editor.template('{it} {air_noun} {be} {neg_adj}.', it=['That', 'This', 'The'], be=['is', 'was'], labels=0, save=True)\n",
    "t += editor.template('{it} {be} {a:neg_adj} {air_noun}.', it=['It', 'This', 'That'], be=['is', 'was'], labels=0, save=True)\n",
    "t += editor.template('{i} {neg_verb} {the} {air_noun}.', i=['I', 'We'], the=['this', 'that', 'the'], labels=0, save=True)\n",
    "\n",
    "# **t means unpacking the dictionary into keyword argument\n",
    "test = MFT(**t)\n",
    "suite.add(test, 'Sentiment-laden words in context', 'Vocabulary', 'Use positive and negative verbs and adjectives with airline nouns such as seats, pilot, flight, etc. E.g. \"This was a bad flight\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['see', 'find', 'saw', 'found']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add dictionary of word into object \n",
    "editor.lexicons['neutral_verb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the test. On each line provided different context with the mask provided\n",
    "t = editor.template('{it} {air_noun} {be} {neutral_adj}.', it=['That', 'This', 'The'], be=['is', 'was'], save=True) #need to define first\n",
    "t += editor.template('{it} {be} {a:neutral_adj} {air_noun}.', it=['It', 'This', 'That'], be=['is', 'was'], save=True) #after first line needed to use += to append test on the list\n",
    "t += editor.template('{i} {neutral_verb} {the} {air_noun}.', i=['I', 'We'], the=['this', 'that', 'the'], save=True)\n",
    "test = MFT(t.data, labels=1, templates=t.templates)\n",
    "suite.add(test, 'neutral words in context', 'Vocabulary', 'Use neutral verbs and adjectives with airline nouns such as seats, pilot, flight, etc. E.g. \"The pilot is American\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intensifiers and reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very , really , truly , absolutely , pretty , quite , incredibly , extremely , most , just , amazingly , utterly , unbelievably , totally , simply , rather , almost , extraordinarily , genuinely , especially , exceptionally , equally , absolute , entirely , certainly , obviously , altogether , exceedingly , fairly , enormously , unexpectedly , insanely , undeniably , particularly , seriously , immensely , unusually , extraordinary , overwhelmingly , otherwise , overall , amazing , surprisingly , admittedly , incredible , actually , completely , appropriately , fucking , all\n"
     ]
    }
   ],
   "source": [
    "# suggest the mask from the context. In this context mask provided the adverb\n",
    "print(' , '.join(editor.suggest('{it} {be} {a:mask} {pos_adj} {air_noun}.', it=['It', 'This', 'That'], be=['is', 'was'])[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define adverb\n",
    "intens_adj = ['very', 'really', 'absolutely', 'truly', 'extremely', 'quite', 'incredibly', 'amazingly', 'especially', 'exceptionally', 'unbelievably', 'utterly', 'exceedingly', 'rather', 'totally', 'particularly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "really, always, just, also, definitely, still, actually, certainly, truly, absolutely, never, greatly, especially, quite, so, particularly, personally, highly, thoroughly, totally, do, only, very, rather, sure, sincerely, honestly, did, completely, genuinely, obviously, even, strongly, much, already, most, immediately, clearly, simply, deeply, fully, mostly, both, have, seriously, almost, generally, too, feel, would, often, again, kinda, usually, finally, all, hugely, specifically, surely, should, dearly, basically, could, had, REALLY, felt, will, now, fucking, ..., can, tremendously, desperately, probably, must, cannot, â€¦, immensely, might, extremely, ultimately, literally, ever, may, incredibly, frankly, secretly, I, more, think, was, were, instantly, gotta, vastly, forever, normally, sorely, quickly, long\n"
     ]
    }
   ],
   "source": [
    "# suggest the mask from the context. In this context mask provided the adverb\n",
    "print(', '.join(editor.suggest('{i} {mask} {pos_verb} {the} {air_noun}.', i=['I', 'We'], the=['this', 'that', 'the'])[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define adverb\n",
    "intens_verb = [ 'really', 'absolutely', 'truly', 'extremely',  'especially',  'utterly',  'totally', 'particularly', 'highly', 'definitely', 'certainly', 'genuinely', 'honestly', 'strongly', 'sure', 'sincerely']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic_label = Expect.monotonic(increasing=True, tolerance=0.1) #label the model: prediction is increasing like pattern and tolerance=0.1. \n",
    "non_neutral_pred = lambda pred, *args, **kwargs: pred != 1 #to check that the neutral is not equal 1, used to filter the neutral out\n",
    "monotonic_label = Expect.slice_pairwise(monotonic_label, non_neutral_pred) #combine label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['It was a fantastic service.', 'It was a quite fantastic service.'],\n",
       " ['That was a great cabin crew.', 'That was an utterly great cabin crew.'],\n",
       " ['It is an exciting staff.', 'It is an exceedingly exciting staff.'],\n",
       " ['It is a good cabin crew.', 'It is an especially good cabin crew.'],\n",
       " ['It was an awesome seat.', 'It was a particularly awesome seat.']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add dictionary of word into object \n",
    "# need to define first then, use `+=` to add. for protecting duplicating problem\n",
    "t = editor.template(['{it} {be} {a:pos_adj} {air_noun}.', '{it} {be} {a:intens} {pos_adj} {air_noun}.'] , intens=intens_adj, it=['It', 'This', 'That'], be=['is', 'was'], nsamples=500, save=True)\n",
    "t += editor.template(['{i} {pos_verb} {the} {air_noun}.', '{i} {intens} {pos_verb} {the} {air_noun}.'], intens=intens_verb, i=['I', 'We'], the=['this', 'that', 'the'], nsamples=500, save=True)\n",
    "t += editor.template(['{it} {be} {a:neg_adj} {air_noun}.', '{it} {be} {a:intens} {neg_adj} {air_noun}.'] , intens=intens_adj, it=['It', 'This', 'That'], be=['is', 'was'], nsamples=500, save=True)\n",
    "t += editor.template(['{i} {neg_verb} {the} {air_noun}.', '{i} {intens} {neg_verb} {the} {air_noun}.'], intens=intens_verb, i=['I', 'We'], the=['this', 'that', 'the'], nsamples=500, save=True)\n",
    "t.data[:5] #show array in 5 list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dictionary of word into object \n",
    "# need to define first then, use `+=` to add. for protecting duplicating problem\n",
    "t = editor.template(['{it} {be} {a:pos_adj} {air_noun}.', '{it} {be} {a:intens} {pos_adj} {air_noun}.'] , intens=intens_adj, it=['It', 'This', 'That'], be=['is', 'was'], nsamples=500, save=True)\n",
    "t += editor.template(['{i} {pos_verb} {the} {air_noun}.', '{i} {intens} {pos_verb} {the} {air_noun}.'], intens=intens_verb, i=['I', 'We'], the=['this', 'that', 'the'], nsamples=500, save=True)\n",
    "t += editor.template(['{it} {be} {a:neg_adj} {air_noun}.', '{it} {be} {a:intens} {neg_adj} {air_noun}.'] , intens=intens_adj, it=['It', 'This', 'That'], be=['is', 'was'], nsamples=500, save=True)\n",
    "t += editor.template(['{i} {neg_verb} {the} {air_noun}.', '{i} {intens} {neg_verb} {the} {air_noun}.'], intens=intens_verb, i=['I', 'We'], the=['this', 'that', 'the'], nsamples=500, save=True)\n",
    "test = DIR(t.data, monotonic_label, templates=t.templates) #used the monotonic_label\n",
    "description = '''Test is composed of pairs of sentences (x1, x2), where we add an intensifier\n",
    "such as \"really\",or \"very\" to x2 and expect the confidence to NOT go down (with tolerance=0.1). e.g.:\n",
    "x1 = \"That was a good flight\"\n",
    "x2 = \"That was a very good flight\"\n",
    "We disregard cases where the prediction of x1 is neutral.\n",
    "'''\n",
    "#add the test into suite\n",
    "suite.add(test, 'intensifiers', 'Vocabulary', description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reducer adjective to reduce the meaning.\n",
    "reducer_adj = ['somewhat', 'kinda', 'mostly', 'probably', 'generally', 'reasonably', 'a little', 'a bit', 'slightly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic_label_down = Expect.monotonic(increasing=False, tolerance=0.1) #label the model: prediction is increasing like pattern and tolerance=0.1. \n",
    "monotonic_label_down = Expect.slice_pairwise(monotonic_label_down, non_neutral_pred) #combine label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The seat is extraordinary.', 'The seat is reasonably extraordinary.'],\n",
       " ['This food was perfect.', 'This food was slightly perfect.'],\n",
       " ['That company is nice.', 'That company is mostly nice.'],\n",
       " ['This customer service is great.',\n",
       "  'This customer service is a little great.'],\n",
       " ['The seat was brilliant.', 'The seat was a little brilliant.'],\n",
       " ['That crew was adorable.', 'That crew was a bit adorable.'],\n",
       " ['That company is amazing.', 'That company is reasonably amazing.'],\n",
       " ['The crew is fantastic.', 'The crew is slightly fantastic.'],\n",
       " ['The cabin crew was good.', 'The cabin crew was mostly good.'],\n",
       " ['That customer service is brilliant.',\n",
       "  'That customer service is generally brilliant.'],\n",
       " ['This staff was exciting.', 'This staff was kinda exciting.'],\n",
       " ['That flight is happy.', 'That flight is generally happy.'],\n",
       " ['The flight was great.', 'The flight was somewhat great.'],\n",
       " ['That customer service was brilliant.',\n",
       "  'That customer service was a bit brilliant.'],\n",
       " ['That customer service was amazing.',\n",
       "  'That customer service was a little amazing.'],\n",
       " ['This company is excellent.', 'This company is reasonably excellent.'],\n",
       " ['This company is happy.', 'This company is a bit happy.'],\n",
       " ['That food is awesome.', 'That food is generally awesome.'],\n",
       " ['That customer service is excellent.',\n",
       "  'That customer service is mostly excellent.'],\n",
       " ['That cabin crew is brilliant.', 'That cabin crew is kinda brilliant.'],\n",
       " ['This pilot was good.', 'This pilot was generally good.'],\n",
       " ['The staff is beautiful.', 'The staff is kinda beautiful.'],\n",
       " ['That flight was great.', 'That flight was kinda great.'],\n",
       " ['The aircraft is good.', 'The aircraft is probably good.'],\n",
       " ['This customer service is happy.', 'This customer service is mostly happy.'],\n",
       " ['This staff is amazing.', 'This staff is kinda amazing.'],\n",
       " ['This seat was brilliant.', 'This seat was kinda brilliant.'],\n",
       " ['This flight is great.', 'This flight is somewhat great.'],\n",
       " ['That flight was incredible.', 'That flight was mostly incredible.'],\n",
       " ['This customer service was awesome.',\n",
       "  'This customer service was kinda awesome.'],\n",
       " ['That airline is nice.', 'That airline is generally nice.'],\n",
       " ['The flight is fantastic.', 'The flight is probably fantastic.'],\n",
       " ['This plane is happy.', 'This plane is somewhat happy.'],\n",
       " ['The cabin crew was fantastic.', 'The cabin crew was reasonably fantastic.'],\n",
       " ['That service was exciting.', 'That service was a little exciting.'],\n",
       " ['This airline is extraordinary.',\n",
       "  'This airline is reasonably extraordinary.'],\n",
       " ['That food is wonderful.', 'That food is kinda wonderful.'],\n",
       " ['This staff is adorable.', 'This staff is generally adorable.'],\n",
       " ['This staff is sweet.', 'This staff is mostly sweet.'],\n",
       " ['This airline is sweet.', 'This airline is reasonably sweet.'],\n",
       " ['The service is nice.', 'The service is probably nice.'],\n",
       " ['The company was adorable.', 'The company was a little adorable.'],\n",
       " ['That customer service is fantastic.',\n",
       "  'That customer service is probably fantastic.'],\n",
       " ['That airline is wonderful.', 'That airline is somewhat wonderful.'],\n",
       " ['That seat is beautiful.', 'That seat is slightly beautiful.'],\n",
       " ['The company was sweet.', 'The company was mostly sweet.'],\n",
       " ['The seat is wonderful.', 'The seat is slightly wonderful.'],\n",
       " ['That aircraft is perfect.', 'That aircraft is generally perfect.'],\n",
       " ['The customer service was incredible.',\n",
       "  'The customer service was reasonably incredible.'],\n",
       " ['The customer service is nice.', 'The customer service is probably nice.']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add dictionary of word into object \n",
    "# need to define first then, use `+=` to add. for protecting duplicating problem\n",
    "t = editor.template(['{it} {air_noun} {be} {pos_adj}.', '{it} {air_noun} {be} {red} {pos_adj}.'] , red=reducer_adj, it=['The', 'This', 'That'], be=['is', 'was'], nsamples=1000, save=True)\n",
    "t += editor.template(['{it} {air_noun} {be} {neg_adj}.', '{it} {air_noun} {be} {red} {neg_adj}.'] , red=reducer_adj, it=['The', 'This', 'That'], be=['is', 'was'], nsamples=1000, save=True)\n",
    "t.data[:50] #show array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dictionary of word into object \n",
    "# need to define first then, use `+=` to add. for protecting duplicating problem\n",
    "t = editor.template(['{it} {air_noun} {be} {pos_adj}.', '{it} {air_noun} {be} {red} {pos_adj}.'] , red=reducer_adj, it=['The', 'This', 'That'], be=['is', 'was'], nsamples=1000, save=True)\n",
    "t += editor.template(['{it} {air_noun} {be} {neg_adj}.', '{it} {air_noun} {be} {red} {neg_adj}.'] , red=reducer_adj, it=['The', 'This', 'That'], be=['is', 'was'], nsamples=1000, save=True)\n",
    "test = DIR(t.data, monotonic_label_down, templates=t.templates)\n",
    "description = '''Test is composed of pairs of sentences (x1, x2), where we add a reducer\n",
    "such as \"somewhat\", or \"kinda\" to x2 and expect the confidence to NOT go up (with tolerance=0.1). e.g.:\n",
    "x1 = \"The cabin crew was good.\"\n",
    "x2 = \"The cabin crew was somewhat good.\"\n",
    "We disregard cases where the prediction of x1 is neutral.\n",
    "'''\n",
    "\n",
    "#add the test into suite. This test case is about reducer adjective to ne more neutral\n",
    "suite.add(test, 'reducers', 'Vocabulary', description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INVariance: change neutral words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define set of neutral word\n",
    "neutral_words = set(\n",
    "    ['.', 'the', 'The', ',', 'a', 'A', 'and', 'of', 'to', 'it', 'that', 'in',\n",
    "     'this', 'for',  'you', 'there', 'or', 'an', 'by', 'about', 'flight', 'my',\n",
    "     'in', 'of', 'have', 'with', 'was', 'at', 'it', 'get', 'from', 'this', 'Flight', 'plane'\n",
    "    ])\n",
    "\n",
    "forbidden = set(['No', 'no', 'Not', 'not', 'Nothing', 'nothing', 'without', 'but'] + pos_adj + neg_adj + pos_verb_present + pos_verb_past + neg_verb_present + neg_verb_past)\n",
    "\n",
    "# function to change the set of neutral word to other context.\n",
    "def change_neutral(d):\n",
    "    examples = []\n",
    "    subs = []\n",
    "    words_in = [x for x in d.capitalize().split() if x in neutral_words]\n",
    "    if not words_in:\n",
    "        return None\n",
    "    for w in words_in:\n",
    "        suggestions = [x for x in editor.suggest_replace(d, w, beam_size=5, words_and_sentences=True) if x[0] not in forbidden]\n",
    "        examples.extend([x[1] for x in suggestions])\n",
    "        subs.extend(['%s -> %s' % (w, x[0]) for x in suggestions])\n",
    "    if examples:\n",
    "        idxs = np.random.choice(len(examples), min(len(examples), 10), replace=False)\n",
    "        return [examples[i] for i in idxs]#, [subs[i] for i in idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(sentences, change_neutral, nsamples=500)\n",
    "test = INV(t.data) #test type is Invariance\n",
    "\n",
    "# BERT means using `Perturb.perturb(...)`\n",
    "description = 'Change a set of neutral words with other context-appropriate neutral words (using BERT).' \n",
    "suite.add(test, 'change neutral words with BERT', 'Vocabulary', description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add negative and positive phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and add context into positive variable\n",
    "positive = editor.template('I {pos_verb_present} you.').data\n",
    "positive += editor.template('You are {pos_adj}.').data\n",
    "positive += ['I would fly with you again.']\n",
    "positive.remove('You are happy.') #remove feeling meaning\n",
    "\n",
    "# define and add context into negative variable\n",
    "negative = editor.template('I {neg_verb_present} you.').data\n",
    "negative += editor.template('You are {neg_adj}.').data\n",
    "negative += ['Never flying with you again.']\n",
    "\n",
    "# function to add phrase\n",
    "def add_phrase_function(phrases):\n",
    "    def pert(d):\n",
    "        while d[-1].pos_ == 'PUNCT':\n",
    "            d = d[:-1]\n",
    "        d = d.text\n",
    "        ret = [d + '. ' + x for x in phrases]\n",
    "        idx = np.random.choice(len(ret), 10, replace=False)\n",
    "        ret = [ret[i] for i in idx]\n",
    "        return ret\n",
    "    return pert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to change positive sentiment probability after perturbation\n",
    "def positive_change(orig_conf, conf):\n",
    "    softmax = type(orig_conf) in [np.array, np.ndarray]\n",
    "    if not softmax or orig_conf.shape[0] != 3:\n",
    "        raise(Exception('Need prediction function to be softmax with 3 labels (negative, neutral, positive)'))\n",
    "    return orig_conf[0] - conf[0] + conf[2] - orig_conf[2]\n",
    "\n",
    "# If the change in positive sentiment probability is within 0.1, then the result will return True if the total change is equal to or greater than 0, \n",
    "# indicating an increase or no change in positive sentiment. Otherwise, it will return the sum of the calculated change and the tolerance.\n",
    "def diff_up(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
    "    tolerance = 0.1\n",
    "    change = positive_change(orig_conf, conf)\n",
    "    if change + tolerance >= 0:\n",
    "        return True\n",
    "    else:\n",
    "        return change + tolerance\n",
    "    \n",
    "# checks whether the positive sentiment probability has changed by 0.1 or more. If the change is zero or negative, it returns True, \n",
    "# meaning the positive sentiment probability has decreased or stayed the same. Otherwise, it returns the negative value of the change.\n",
    "def diff_down(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
    "    tolerance = 0.1\n",
    "    change = positive_change(orig_conf, conf)\n",
    "    if change - tolerance <= 0:\n",
    "        return True\n",
    "    else:\n",
    "        return -(change - tolerance)\n",
    "\n",
    "goes_up = Expect.pairwise(diff_up) #for adding positive phrase\n",
    "goes_down = Expect.pairwise(diff_down) #for adding negative phrase\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test case provided the adding very positive test. When adding the very positive phrase, the probabilily of positive will not go down\n",
    "t = Perturb.perturb(parsed_data, add_phrase_function(positive), nsamples=500)\n",
    "test = DIR(t.data, goes_up) \n",
    "description = 'Add very positive phrases (e.g. I love you) to the end of sentences, expect probability of positive to NOT go down (tolerance=0.1)'\n",
    "suite.add(test, 'add positive phrases', 'Vocabulary', description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test case provided the adding very negative test. When adding the very negative phrase, the probabilily of positive will not go up\n",
    "t = Perturb.perturb(parsed_data, add_phrase_function(negative), nsamples=500)\n",
    "test = DIR(t.data, goes_down)\n",
    "description = 'Add very negative phrases (e.g. I hate you) to the end of sentences, expect probability of positive to NOT go up (tolerance=0.1)'\n",
    "suite.add(test, 'add negative phrases', 'Vocabulary', description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: robustness\n",
    "### INVariance: adding irrelevant stuff before and after.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# generate random string\n",
    "def random_string(n):\n",
    "    return ''.join(np.random.choice([x for x in string.ascii_letters + string.digits], n))\n",
    "\n",
    "# generate random urls with the random url\n",
    "def random_url(n=6):\n",
    "    return 'https://t.co/%s' % random_string(n)\n",
    "\n",
    "#generates a random Twitter handle in the `@%s`format\n",
    "def random_handle(n=6):\n",
    "    return '@%s' % random_string(n)\n",
    "\n",
    "# function that used to add the irrelevant data\n",
    "def add_irrelevant(sentence):\n",
    "    urls_and_handles = [random_url(n=6) for _ in range(5)] + [random_handle() for _ in range(5)]\n",
    "    irrelevant_before = ['@airline '] + urls_and_handles\n",
    "    irrelevant_after = urls_and_handles \n",
    "    rets = ['%s %s' % (x, sentence) for x in irrelevant_before ]\n",
    "    rets += ['%s %s' % (sentence, x) for x in irrelevant_after]\n",
    "    return rets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test case is used for testing if adding random url and handle at the start or end function. \n",
    "t = Perturb.perturb(sentences, add_irrelevant, nsamples=500)\n",
    "test = INV(t.data)\n",
    "suite.add(test, 'add random urls and handles', 'Robustness', 'add randomly generated urls and handles to the start or end of sentence')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### punctuation, contractions, typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test case provided the punctuation \n",
    "t = Perturb.perturb(parsed_data, Perturb.punctuation, nsamples=500)\n",
    "test = INV(t.data)\n",
    "suite.add(test, 'punctuation', 'Robustness', 'strip punctuation and / or add \".\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test case provided the typos test. e.g., `;` `?`\n",
    "t = Perturb.perturb(sentences, Perturb.add_typos, nsamples=500, typos=1)\n",
    "test = INV(t.data)\n",
    "suite.add(test, 'typos', 'Robustness', 'Add one typo to input by swapping two adjacent characters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test case provided the 2 typos in test. e.g., `;` `?`\n",
    "t = Perturb.perturb(sentences, Perturb.add_typos, nsamples=500, typos=2)\n",
    "test = INV(t.data)\n",
    "suite.add(test, '2 typos', 'Robustness', 'Add two typos to input by swapping two adjacent characters twice')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this test case about expanding the contraction. For example; do not -> don't\n",
    "t = Perturb.perturb(sentences, Perturb.contractions, nsamples=1000)\n",
    "test = INV(t.data)\n",
    "suite.add(test, 'contractions', 'Robustness', 'Contract or expand contractions, e.g. What is -> What\\'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test case about adding the Perturb names. Replace the name with common names\n",
    "t = Perturb.perturb(parsed_data, Perturb.change_names, nsamples=1000)\n",
    "test = INV(t.data)\n",
    "suite.add(test, 'change names', 'NER', 'Replace names with other common names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test case about adding the Perturb location names. Replace the name with other location names\n",
    "t = Perturb.perturb(parsed_data, Perturb.change_location, nsamples=1000)\n",
    "test = INV(t.data)\n",
    "suite.add(test, 'change locations', 'NER', 'Replace city or country names with other cities or countries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: temporal awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate', 'dislike', 'regret', 'abhor', 'dread', 'despise']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whats include in object `neg_verb_present`\n",
    "editor.template('{neg_verb_present}').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dictionary of word into object \n",
    "change = ['but', 'even though', 'although', '']\n",
    "\n",
    "# need to define first then, use `+=` to add. for protecting duplicating problem\n",
    "t = editor.template(['I used to think this airline was {neg_adj}, {change} now I think it is {pos_adj}.',\n",
    "                                 'I think this airline is {pos_adj}, {change} I used to think it was {neg_adj}.',\n",
    "                                 'In the past I thought this airline was {neg_adj}, {change} now I think it is {pos_adj}.',\n",
    "                                 'I think this airline is {pos_adj}, {change} in the past I thought it was {neg_adj}.',\n",
    "                                ] ,\n",
    "                                 change=change, unroll=True, nsamples=500, save=True, labels=2)\n",
    "t += editor.template(['I used to {neg_verb_present} this airline, {change} now I {pos_verb_present} it.',\n",
    "                                 'I {pos_verb_present} this airline, {change} I used to {neg_verb_present} it.',\n",
    "                                 'In the past I would {neg_verb_present} this airline, {change} now I {pos_verb} it.',\n",
    "                                 'I {pos_verb_present} this airline, {change} in the past I would {neg_verb_present} it.',\n",
    "                                ] ,\n",
    "                                change=change, unroll=True, nsamples=500, save=True, labels=2)\n",
    "\n",
    "t += editor.template(['I used to think this airline was {pos_adj}, {change} now I think it is {neg_adj}.',\n",
    "                                 'I think this airline is {neg_adj}, {change} I used to think it was {pos_adj}.',\n",
    "                                 'In the past I thought this airline was {pos_adj}, {change} now I think it is {neg_adj}.',\n",
    "                                 'I think this airline is {neg_adj}, {change} in the past I thought it was {pos_adj}.',\n",
    "                                ] ,\n",
    "                                 change=change, unroll=True, nsamples=500, save=True, labels=0)\n",
    "t += editor.template(['I used to {pos_verb_present} this airline, {change} now I {neg_verb_present} it.',\n",
    "                                 'I {neg_verb_present} this airline, {change} I used to {pos_verb_present} it.',\n",
    "                                 'In the past I would {pos_verb_present} this airline, {change} now I {neg_verb_present} it.',\n",
    "                                 'I {neg_verb_present} this airline, {change} in the past I would {pos_verb_present} it.',\n",
    "                                ] ,\n",
    "                                change=change, unroll=True, nsamples=500, save=True, labels=0)\n",
    "test = MFT(**t) # basic function test\n",
    "description = '''Have two conflicing statements, one about the past and one about the present.\n",
    "Expect the present to carry the sentiment. Examples:\n",
    "I used to love this airline, now I hate it -> should be negative\n",
    "I love this airline, although I used to hate it -> should be positive\n",
    "'''\n",
    "suite.add(test, 'used to, but now', 'Temporal', description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used to should reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it is a good flight.', 'I used to think it is a good flight.'],\n",
       " ['it is a good seat.', 'I used to think it is a good seat.'],\n",
       " ['it is a good pilot.', 'I used to think it is a good pilot.'],\n",
       " ['it is a good staff.', 'I used to think it is a good staff.'],\n",
       " ['it is a good service.', 'I used to think it is a good service.']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the data, add more context. To reduce the meaning feeling to become less strong meaning.\n",
    "t = editor.template(['{it} {be} {a:adj} {air_noun}.', 'I used to think {it} {be} {a:adj} {air_noun}.'], it=['it', 'this', 'that'], be=['is', 'was'], adj=editor.lexicons['pos_adj'] + editor.lexicons['neg_adj'], save=True)\n",
    "t += editor.template(['{i} {verb} {the} {air_noun}.', '{i} used to {verb} {the} {air_noun}.'], i=['I', 'We'], the=['this', 'that', 'the'], verb=editor.lexicons['pos_verb_present'] + editor.lexicons['neg_verb_present'], save=True)\n",
    "t.data[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the test case: add used to reduce confidence\n",
    "t = editor.template(['{it} {be} {a:adj} {air_noun}.', 'I used to think {it} {be} {a:adj} {air_noun}.'], it=['it', 'this', 'that'], be=['is', 'was'], adj=editor.lexicons['pos_adj'] + editor.lexicons['neg_adj'], save=True)\n",
    "t += editor.template(['{i} {verb} {the} {air_noun}.', '{i} used to {verb} {the} {air_noun}.'], i=['I', 'We'], the=['this', 'that', 'the'], verb=editor.lexicons['pos_verb_present'] + editor.lexicons['neg_verb_present'], save=True)\n",
    "test = DIR(t.data, monotonic_label_down, templates=t.templates)\n",
    "suite.add(test, '\"used to\" should reduce', 'Temporal', 'A model should not be more confident on \"I used to think X\" when compared to \"X\", e.g. \"I used to love this airline\" should have less confidence than \"I love this airline\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability: Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['male', 'female', 'first_name', 'first_pronoun', 'last_name', 'country', 'nationality', 'city', 'religion', 'religion_adj', 'sexual_adj', 'sentiment', 'country_city', 'male_from', 'female_from', 'last_from', 'air_noun', 'pos_adj', 'neg_adj', 'neutral_adj', 'pos_verb_present', 'neg_verb_present', 'neutral_verb_present', 'pos_verb_past', 'neg_verb_past', 'neutral_verb_past', 'pos_verb', 'neg_verb', 'neutral_verb'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor.lexicons.keys() #suggest the word. help to have more ideas to add into object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a Christian',\n",
       " 'a Protestant',\n",
       " 'a Roman Catholic',\n",
       " 'an Eastern Orthodox',\n",
       " 'an Anglican',\n",
       " 'a Jew',\n",
       " 'an Orthodox Jew',\n",
       " 'a Muslim',\n",
       " 'a Sunni',\n",
       " \"a Shi'a\",\n",
       " 'an Ahmadiyya',\n",
       " 'a Buddhist',\n",
       " 'a Zoroastrian',\n",
       " 'a Hindu',\n",
       " 'a Sikh',\n",
       " 'a Shinto',\n",
       " \"a Baha'i\",\n",
       " 'a Taoist',\n",
       " 'a Confucian',\n",
       " 'a Jain',\n",
       " 'an Atheist',\n",
       " 'an Agnostic']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor.template('{a:religion_adj}').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dictionary of word into object \n",
    "# this protect is to protect that might be sensible\n",
    "protected = {\n",
    "    'race': ['a black','a hispanic', 'a white', 'an asian'],\n",
    "    'sexual': editor.template('{a:sexual_adj}').data,\n",
    "    'religion': editor.template('{a:religion_adj}').data,\n",
    "    'nationality': editor.template('{a:nationality}').data[:20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race\n",
      "sexual\n",
      "religion\n",
      "nationality\n"
     ]
    }
   ],
   "source": [
    "# Add the test case about Fairness. Prediction should be the same if there has the various adjective\n",
    "for p, vals in protected.items():\n",
    "    print(p)\n",
    "    t = editor.template(['{male} is %s {mask}.' % r for r in vals], return_maps=False, nsamples=300, save=True)\n",
    "    t += editor.template(['{female} is %s {mask}.' % r for r in vals], return_maps=False, nsamples=300, save=True)\n",
    "    test = INV(t.data, threshold=0.1, templates=t.templates)\n",
    "    suite.add(test, 'protected: %s' % p, 'Fairness', 'Prediction should be the same for various adjectives within a protected class')\n",
    "#     test.run(new_pp)\n",
    "#     test.summary(n=3)\n",
    "#     print()\n",
    "#     preds = np.array(test.results.preds)\n",
    "#     for i, x in enumerate(vals):\n",
    "#         print('%.2f %s' % (preds[:, i].mean(), vals[i]))\n",
    "#     print()\n",
    "#     print()\n",
    "#     print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Capability: Negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the simple negation test case\n",
    "t = editor.template('{it} {air_noun} {nt} {pos_adj}.', it=['This', 'That', 'The'], nt=['is not', 'isn\\'t'], save=True)\n",
    "t += editor.template('{it} {benot} {a:pos_adj} {air_noun}.', it=['It', 'This', 'That'], benot=['is not',  'isn\\'t', 'was not', 'wasn\\'t'], save=True)\n",
    "neg = ['I can\\'t say I', 'I don\\'t', 'I would never say I', 'I don\\'t think I', 'I didn\\'t' ]\n",
    "t += editor.template('{neg} {pos_verb_present} {the} {air_noun}.', neg=neg, the=['this', 'that', 'the'], save=True)\n",
    "t += editor.template('No one {pos_verb_present}s {the} {air_noun}.', neg=neg, the=['this', 'that', 'the'], save=True)\n",
    "test = MFT(t.data, labels=0, templates=t.templates)\n",
    "suite.add(test, 'simple negations: negative', 'Negation', 'Very simple negations of positive statements')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the simple negation test case.\n",
    "t = editor.template('{it} {air_noun} {nt} {neg_adj}.', it=['This', 'That', 'The'], nt=['is not', 'isn\\'t'], save=True)\n",
    "t += editor.template('{it} {benot} {a:neg_adj} {air_noun}.', it=['It', 'This', 'That'], benot=['is not',  'isn\\'t', 'was not', 'wasn\\'t'], save=True)\n",
    "neg = ['I can\\'t say I', 'I don\\'t', 'I would never say I', 'I don\\'t think I', 'I didn\\'t' ]\n",
    "t += editor.template('{neg} {neg_verb_present} {the} {air_noun}.', neg=neg, the=['this', 'that', 'the'], save=True)\n",
    "t += editor.template('No one {neg_verb_present}s {the} {air_noun}.', neg=neg, the=['this', 'that', 'the'], save=True)\n",
    "# expectation: prediction is not 0\n",
    "is_not_0 = lambda x, pred, *args: pred != 0 # expect not equal 0 means not equal to negative that label when importing the csv\n",
    "test = MFT(t.data, Expect.single(is_not_0), templates=t.templates)\n",
    "suite.add(test, 'simple negations: not negative', 'Negation', 'Very simple negations of negative statements. Expectation requires prediction to NOT be negative (i.e. neutral or positive)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add not neutral is still neutral test case\n",
    "# e.g., I thought the airline would be Italian, but it wasn't. \n",
    "t = editor.template('{it} {air_noun} {nt} {neutral_adj}.', it=['This', 'That', 'The'], nt=['is not', 'isn\\'t'], save=True)\n",
    "t += editor.template('{it} {benot} {a:neutral_adj} {air_noun}.', it=['It', 'This', 'That'], benot=['is not',  'isn\\'t', 'was not', 'wasn\\'t'], save=True)\n",
    "neg = ['I can\\'t say I', 'I don\\'t', 'I would never say I', 'I don\\'t think I', 'I didn\\'t' ]\n",
    "t += editor.template('{neg} {neutral_verb_present} {the} {air_noun}.', neg=neg, the=['this', 'that', 'the'], save=True)\n",
    "test = MFT(t.data, labels=1, templates=t.templates)\n",
    "suite.add(test, 'simple negations: not neutral is still neutral', 'Negation', 'Negating neutral statements should still result in neutral predictions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_noun_it = [x for x in editor.lexicons['air_noun'] if x != 'pilot'] # without using `pilot` because it needs to use object not person\n",
    "t = editor.template('I thought {it} {air_noun} would be {pos_adj}, but it {neg}.', air_noun=air_noun_it, neg=['was not', 'wasn\\'t'], it=['this', 'that', 'the'], nt=['is not', 'isn\\'t'], save=True)\n",
    "t += editor.template('I thought I would {pos_verb_present} {the} {air_noun}, but I {neg}.', neg=['did not', 'didn\\'t'], the=['this', 'that', 'the'], save=True)\n",
    "test = MFT(t.data, labels=0, templates=t.templates) # expect to be negative\n",
    "suite.add(test, 'simple negations: I thought x was positive, but it was not (should be negative)', 'Negation', '', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., I thought I would despise the company, but I didn't.\n",
    "t = editor.template('I thought {it} {air_noun} would be {neg_adj}, but it {neg}.', air_noun=air_noun_it, neg=['was not', 'wasn\\'t'], it=['this', 'that', 'the'], nt=['is not', 'isn\\'t'], save=True)\n",
    "t += editor.template('I thought I would {neg_verb_present} {the} {air_noun}, but I {neg}.', neg=['did not', 'didn\\'t'], the=['this', 'that', 'the'], save=True)\n",
    "# expectation: prediction is not 0 (negative)\n",
    "test = MFT(t.data, Expect.single(is_not_0), templates=t.templates)\n",
    "suite.add(test, 'simple negations: I thought x was negative, but it was not (should be neutral or positive)', 'Negation', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., I thought the airline would be Italian, but it wasn't\n",
    "t = editor.template('I thought {it} {air_noun} would be {neutral_adj}, but it {neg}.', air_noun=air_noun_it, neg=['was not', 'wasn\\'t'], it=['this', 'that', 'the'], nt=['is not', 'isn\\'t'], save=True)\n",
    "t += editor.template('I thought I would {neutral_verb_present} {the} {air_noun}, but I {neg}.', neg=['did not', 'didn\\'t'], the=['this', 'that', 'the'], save=True)\n",
    "# expectation: prediction is not 0 (negative)\n",
    "test = MFT(t.data, labels=1, templates=t.templates) # label = 1 means expect to be  Neutral\n",
    "suite.add(test, 'simple negations: but it was not (neutral) should still be neutral', 'Negation', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harder: negation with neutral in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the test case: negation with neutral in the middle.\n",
    "# e.g.,  I wouldn't say, given my history with airplanes, that this pilot is excellent.\n",
    "# expect to be negative\n",
    "neutral =['that I am from Brazil', 'my history with airplanes', 'all that I\\'ve seen over the years', 'the time that I\\'ve been flying', 'it\\'s a Tuesday']\n",
    "t = editor.template('{neg}, given {neutral}, that {it} {air_noun} {be} {pos_adj}.', neutral=neutral, neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], it=['this', 'that', 'the'], be=['is', 'was'], save=True)\n",
    "t += editor.template('{neg}, given {neutral}, that {it} {be} {a:pos_adj} {air_noun}.',neutral=neutral,  neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], it=['this', 'that', 'the'], be=['is', 'was'], save=True)\n",
    "t += editor.template('{neg}, given {neutral}, that {i} {pos_verb_present} {the} {air_noun}.',neutral=neutral,  neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], i=['I', 'we'], the=['this', 'that', 'the'], save=True)\n",
    "t.data = list(np.random.choice(t.data, 1000, replace=False))\n",
    "test = MFT(t.data, labels=0, templates=t.templates)\n",
    "suite.add(test, 'Hard: Negation of positive with neutral stuff in the middle (should be negative)', 'Negation', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the test case: negation with neutral in the middle.\n",
    "# e.g., I don't think, given all that I've seen over the years, that the service is difficult.\n",
    "# expect to be positive or neutral\n",
    "neutral =['that I am from Brazil', 'my history with airplanes', 'all that I\\'ve seen over the years', 'the time that I\\'ve been flying', 'it\\'s a Tuesday']\n",
    "t = editor.template('{neg}, given {neutral}, that {it} {air_noun} {be} {neg_adj}.', neutral=neutral, neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], it=['this', 'that', 'the'], be=['is', 'was'], save=True)\n",
    "t += editor.template('{neg}, given {neutral}, that {it} {be} {a:neg_adj} {air_noun}.',neutral=neutral,  neg=['i don\\'t think', 'i can\\'t say', 'i wouldn\\'t say'], it=['this', 'that', 'the'], be=['is', 'was'], save=True)\n",
    "t += editor.template('{neg}, given {neutral}, that {i} {neg_verb_present} {the} {air_noun}.',neutral=neutral,  neg=['i don\\'t think', 'i can\\'t say', 'i wouldn\\'t say'], i=['I', 'we'], the=['this', 'that', 'the'], save=True)\n",
    "t.data = list(np.random.choice(t.data, 1000, replace=False))\n",
    "test = MFT(t.data, Expect.single(is_not_0), templates=t.templates) #expect that is not the negative\n",
    "suite.add(test, 'Hard: Negation of negative with neutral stuff in the middle (should be positive or neutral)', 'Negation', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the test case: negation with neutral in the middle.\n",
    "# e.g., I can't say, given it's a Tuesday, that that aircraft was British.\n",
    "# expect to be neutral\n",
    "neutral =['that I am from Brazil', 'my history with airplanes', 'all that I\\'ve seen over the years', 'the time that I\\'ve been flying', 'it\\'s a Tuesday']\n",
    "t = editor.template('{neg}, given {neutral}, that {it} {air_noun} {be} {neutral_adj}.', neutral=neutral, neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], it=['this', 'that', 'the'], be=['is', 'was'], save=True)\n",
    "t += editor.template('{neg}, given {neutral}, that {it} {be} {a:neutral_adj} {air_noun}.',neutral=neutral,  neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], it=['this', 'that', 'the'], be=['is', 'was'], save=True)\n",
    "t += editor.template('{neg}, given {neutral}, that {i} {neutral_verb_present} {the} {air_noun}.',neutral=neutral,  neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], i=['I', 'we'], the=['this', 'that', 'the'], save=True)\n",
    "t.data = list(np.random.choice(t.data, 1000, replace=False))\n",
    "test = MFT(t.data, labels=1, templates=t.templates)\n",
    "suite.add(test, 'negation of neutral with neutral in the middle, should still neutral', 'Negation', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Capability: SRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my opinion is more important than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the test case about my opinion is important than others\n",
    "change = [' but', '']\n",
    "templates = ['Some people think you are {neg_adj},{change} I think you are {pos_adj}.',\n",
    "             'I think you are {pos_adj},{change} some people think you are {neg_adj}.',\n",
    "             'I had heard you were {neg_adj},{change} I think you are {pos_adj}.',\n",
    "             'I think you are {pos_adj},{change} I had heard you were {neg_adj}.',\n",
    "             ]\n",
    "t = editor.template(templates, change=change, unroll=True, labels=2, save=True)\n",
    "\n",
    "templates = ['{others} {neg_verb_present} you,{change} I {pos_verb_present} you.',\n",
    "             'I {pos_verb_present} you,{change} {others} {neg_verb_present} you.',\n",
    "            ]\n",
    "others = ['some people', 'my parents', 'my friends', 'people']\n",
    "t += editor.template(templates, others=others, change=change, unroll=True, labels=2, save=True) #expect positive\n",
    "\n",
    "change = [' but', '']\n",
    "templates = ['Some people think you are {pos_adj},{change} I think you are {neg_adj}.',\n",
    "             'I think you are {neg_adj},{change} some people think you are {pos_adj}.',\n",
    "             'I had heard you were {pos_adj},{change} I think you are {neg_adj}.',\n",
    "             'I think you are {neg_adj},{change} I had heard you were {pos_adj}.',\n",
    "             ]\n",
    "t += editor.template(templates, change=change, unroll=True, labels=0, save=True) #expect negative\n",
    "\n",
    "templates = ['{others} {pos_verb_present} you,{change} I {neg_verb_present} you.',\n",
    "             'I {neg_verb_present} you,{change} {others} {pos_verb_present} you.',\n",
    "            ]\n",
    "others = ['some people', 'my parents', 'my friends', 'people']\n",
    "t += editor.template(templates, others=others, change=change, unroll=True, labels=0, save=True) #expect negative\n",
    "\n",
    "test = MFT(**t)\n",
    "description = '''Have conflicting statements where the author has an opinion and a third party has a contrary opinion.\n",
    "Expect sentiment to be the authors'. Example:\n",
    "\"Some people think you are great, but I think you are terrible\" -> should be negative\n",
    "'''\n",
    "suite.add(test, 'my opinion is what matters', 'SRL', description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q & a form: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the q and a test case\n",
    "\n",
    "# e.g., Do I think that food was international? Yes\n",
    "# label positive\n",
    "t = editor.template('Do I think {it} {air_noun} {be} {pos_adj}? Yes', it=['that', 'this', 'the'], be=['is', 'was'], save=True, labels=2)\n",
    "t += editor.template('Do I think {it} {be} {a:pos_adj} {air_noun}? Yes', it=['it', 'this', 'that'], be=['is', 'was'], save=True, labels=2)\n",
    "t += editor.template('Did {i} {pos_verb_present} {the} {air_noun}? Yes', i=['I', 'we'], the=['this', 'that', 'the'], save=True, labels=2)\n",
    "\n",
    "# label negative\n",
    "t += editor.template('Do I think {it} {air_noun} {be} {neg_adj}? Yes', it=['that', 'this', 'the'], be=['is', 'was'], save=True, labels=0)\n",
    "t += editor.template('Do I think {it} {be} {a:neg_adj} {air_noun}? Yes', it=['it', 'this', 'that'], be=['is', 'was'], save=True, labels=0)\n",
    "t += editor.template('Did {i} {neg_verb_present} {the} {air_noun}? Yes', i=['I', 'we'], the=['this', 'that', 'the'], save=True, labels=0)\n",
    "test = MFT(**t)\n",
    "suite.add(test, 'Q & A: yes', 'SRL', 'TODO_DESCRIPTION')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more test case about qna expect to be neutral\n",
    "t = editor.template('Do I think {it} {air_noun} {be} {neutral_adj}? Yes', it=['that', 'this', 'the'], be=['is', 'was'], save=True)\n",
    "t += editor.template('Do I think {it} {be} {a:neutral_adj} {air_noun}? Yes', it=['it', 'this', 'that'], be=['is', 'was'], save=True)\n",
    "t += editor.template('Did {i} {neutral_verb_present} {the} {air_noun}? Yes', i=['I', 'we'], the=['this', 'that', 'the'], save=True)\n",
    "test = MFT(t.data, labels=1, templates=t.templates)\n",
    "suite.add(test, 'Q & A: yes (neutral)', 'SRL', 'TODO_DESCRIPTION')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label negative\n",
    "t = editor.template('Do I think {it} {air_noun} {be} {pos_adj}? No', it=['that', 'this', 'the'], be=['is', 'was'], save=True, labels=0)\n",
    "t += editor.template('Do I think {it} {be} {a:pos_adj} {air_noun}? No', it=['it', 'this', 'that'], be=['is', 'was'], save=True, labels=0)\n",
    "t += editor.template('Did {i} {pos_verb_present} {the} {air_noun}? No', i=['I', 'we'], the=['this', 'that', 'the'], save=True, labels=0)\n",
    "\n",
    "# label to be neutral\n",
    "t += editor.template('Do I think {it} {air_noun} {be} {neg_adj}? No', it=['that', 'this', 'the'], be=['is', 'was'], save=True, labels=1)\n",
    "t += editor.template('Do I think {it} {be} {a:neg_adj} {air_noun}? No', it=['it', 'this', 'that'], be=['is', 'was'], save=True, labels=1)\n",
    "t += editor.template('Did {i} {neg_verb_present} {the} {air_noun}? No', i=['I', 'we'], the=['this', 'that', 'the'], save=True, labels=1)\n",
    "\n",
    "# firstly, if label=1 (neutral),then check that is not negative. otherwise, pred label equal to label\n",
    "allow_for_neutral = lambda x, pred, _, label, _2 : pred != 0 if label == 1 else pred == label\n",
    "test = MFT(t.data, Expect.single(allow_for_neutral), labels=t.labels, templates=t.templates) #when testing, expect label to be the same\n",
    "suite.add(test, 'Q & A: no', 'SRL', 'TODO_DESCRIPTION')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case that have `no` answer. \n",
    "t = editor.template('Do I think {it} {air_noun} {be} {neutral_adj}? No', it=['that', 'this', 'the'], be=['is', 'was'], save=True)\n",
    "t += editor.template('Do I think {it} {be} {a:neutral_adj} {air_noun}? No', it=['it', 'this', 'that'], be=['is', 'was'], save=True)\n",
    "t += editor.template('Did {i} {neutral_verb_present} {the} {air_noun}? No', i=['I', 'we'], the=['this', 'that', 'the'], save=True)\n",
    "\n",
    "# expect to be neutral\n",
    "test = MFT(t.data, labels=1, templates=t.templates)\n",
    "suite.add(test, 'Q & A: no (neutral)', 'SRL', 'TODO_DESCRIPTION')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameter name\n",
    "for test in suite.tests:\n",
    "    suite.tests[test].name = test\n",
    "    suite.tests[test].description = suite.info[test]['description]']\n",
    "    suite.tests[test].capability = suite.info[test]['capability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'sentiment_suite.pkl' # define path\n",
    "suite.save(path) # save suite (test case) to the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
